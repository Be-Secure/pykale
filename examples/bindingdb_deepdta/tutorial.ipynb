{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dda9ef8",
   "metadata": {},
   "source": [
    "# PyKale Tutorial: Drug-Target Interaction: DeepDTA\n",
    "\n",
    "|[Launch Binder](https://mybinder.org/v2/gh/pykale/pykale/HEAD?filepath=examples%2Fbindingdb_deepdta%2Ftutorial.ipynb) | [Open In Colab](https://colab.research.google.com/github/pykale/pykale/blob/main/examples/bindingdb_deepdta/tutorial.ipynb)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277595d5",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first few blocks of code are necessary to set up the notebook execution environment and import the required modules, including PyKale.\n",
    "\n",
    "This checks if the notebook is running on Google Colab and installs required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()    \n",
    "\n",
    "    !git clone -b bindingdb_deepdta_tutorial https://github.com/pykale/pykale.git\n",
    "\n",
    "    !conda env update -n base -f pykale/environment.yml\n",
    "    \n",
    "    %cd  pykale/examples/bindingdb_deepdta\n",
    "else:\n",
    "    print('Not running on CoLab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8fa71",
   "metadata": {},
   "source": [
    "This imports required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from config import get_cfg_defaults\n",
    "from model import get_model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from kale.loaddata.tdc_datasets import BindingDBDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfa7ff",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The configuration used in this tutorial is stored in `./configs/tutorial.yaml`, this file overwrites defaults in `config.py` where a value is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"./configs/tutorial.yaml\"\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(cfg_path)\n",
    "cfg.freeze()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ffb872",
   "metadata": {},
   "source": [
    "## Check if a GPU is available\n",
    "\n",
    "If a CUDA GPU is available, this should be used to accelerate the training process. The code below checks and reports on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using: \" + device)\n",
    "gpus = 1 if device == \"cuda\" else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a81b10",
   "metadata": {},
   "source": [
    "## Select Datasets\n",
    "\n",
    "Source and target datasets are specified using the `BindingDBDataset()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e7f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BindingDBDataset(name=cfg.DATASET.NAME, split=\"train\", path=cfg.DATASET.PATH)\n",
    "val_dataset = BindingDBDataset(name=cfg.DATASET.NAME, split=\"valid\", path=cfg.DATASET.PATH)\n",
    "test_dataset = BindingDBDataset(name=cfg.DATASET.NAME, split=\"test\", path=cfg.DATASET.PATH)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=cfg.SOLVER.TRAIN_BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, shuffle=True, batch_size=cfg.SOLVER.TEST_BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=cfg.SOLVER.TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8cf4a",
   "metadata": {},
   "source": [
    "## Setup model\n",
    "\n",
    "Here, we use the previously defined configuration and dataset to set up the model we will subsequently train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed85c92",
   "metadata": {},
   "source": [
    "## Setup Logger\n",
    "\n",
    "A logger is used to store output generated during and after model training. This information can be used to assess the effectiveness of the training and to identify problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fd90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = TensorBoardLogger(\"tb_logs\", name=cfg.DATASET.NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0042a75",
   "metadata": {},
   "source": [
    "## Setup Trainer\n",
    "\n",
    "A trainer object is used to determine and store model parameters. Here, one is configured with information on how a model should be trained, and what hardware will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\")\n",
    "trainer = pl.Trainer(min_epochs=cfg.SOLVER.MIN_EPOCHS, \n",
    "                     max_epochs=cfg.SOLVER.MAX_EPOCHS, \n",
    "                     gpus=gpus, logger=tb_logger, \n",
    "                     callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e4232",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Optimize model parameters using the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d59022",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0533d",
   "metadata": {},
   "source": [
    "## Test Optimized Model\n",
    "\n",
    "Check performance of model optmized with training data against test data which was not used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(test_dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
